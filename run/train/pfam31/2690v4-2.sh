# export CUDA_VISIBLE_DEVICES=1; python v4-birnn.py --training_data=/home/hotdogee/datasets2/pfam-regions-d0-s20-train.tfrecords --eval_data=/home/hotdogee/datasets2/pfam-regions-d0-s20-test.tfrecords --metadata_path=/home/hotdogee/datasets2/pfam-regions-d0-s20-meta.json --num_classes=16715 --batch_size=2 --save_summary_steps=200 --log_step_count_steps=200 --learning_rate_decay_steps=350000 --learning_rate_decay_rate=0.9 --learning_rate=0.005 --adam_epsilon=0.01 --save_checkpoints_secs=3600 --keep_checkpoint_max=24 --use_cudnn=True --use_crf=False --use_conv_batch_norm=True --use_rnn_batch_norm=True --rnn_cell_type=CudnnGRU --use_conv_1_bank=False --conv_1_filters=32 --conv_1_bank_size=16 --conv_1_strides=1 --use_conv_1_residual=False --use_conv_1_highway=False --conv_1_highway_depth=3 --conv_1_highway_units=32  --use_conv_1_prenet=False --conv_1_prenet_dropout=0.2 --use_conv_1_attention=False --conv_1_attention_units=16 --conv_1_attention_drop_res=0.2 --use_rnn_attention=False --rnn_attention_units=16 --rnn_attention_drop_res=0.2 --use_batch_renorm=True --model_dir=/home/hotdogee/checkpoints/pfam-regions-d0-s20/2690V4-TITANV/v4-birnn/BatchRenorm-lr0.005-ae0.01-2
# export CUDA_VISIBLE_DEVICES=1; python v4-birnn.py --training_data=/home/hotdogee/datasets2/pfam-regions-d0-s20-train.tfrecords --eval_data=/home/hotdogee/datasets2/pfam-regions-d0-s20-test.tfrecords --metadata_path=/home/hotdogee/datasets2/pfam-regions-d0-s20-meta.json --num_classes=16715 --batch_size=2 --save_summary_steps=200 --log_step_count_steps=200 --learning_rate_decay_steps=350000 --learning_rate_decay_rate=0.9 --learning_rate=0.005 --adam_epsilon=0.01 --save_checkpoints_secs=3600 --keep_checkpoint_max=24 --use_cudnn=True --use_crf=False --use_conv_batch_norm=True --use_rnn_batch_norm=True --rnn_cell_type=CudnnGRU --use_conv_1_bank=False --conv_1_filters=32 --conv_1_bank_size=16 --conv_1_strides=1 --use_conv_1_residual=False --use_conv_1_highway=False --conv_1_highway_depth=3 --conv_1_highway_units=32  --use_conv_1_prenet=False --conv_1_prenet_dropout=0.2 --use_batch_renorm=True  --use_conv_1_attention=True --attention_key_channels=32 --attention_value_channels=32 --attention_hidden_size=32 --attention_num_heads=1 --attention_dropout=0.0 --attention_type=local_unmasked --attention_block_length=128 --attention_filter_width=64 --use_conv_1_attention_batch_norm=True --use_rnn_attention=True --rnn_attention_hidden_size=128 --use_rnn_attention_batch_norm=True --model_dir=/home/hotdogee/checkpoints/pfam-regions-d0-s20/2690V4-1080Ti/v4-birnn/LocalAttentionConv32Rnn128-BN-lr0.005-ae0.01-1
# mkdir -p /home/hotdogee/Dropbox/Work/Btools/ANNotate/ANNotate2/checkpoints/pfam-regions-d0-s20/2690V4-1080Ti/v4-birnn/LocalAttentionConv32Rnn128-BN-lr0.005-ae0.01-1/
# ln /home/hotdogee/checkpoints/pfam-regions-d0-s20/2690V4-1080Ti/v4-birnn/LocalAttentionConv32Rnn128-BN-lr0.005-ae0.01-1/event* /home/hotdogee/Dropbox/Work/Btools/ANNotate/ANNotate2/checkpoints/pfam-regions-d0-s20/2690V4-1080Ti/v4-birnn/LocalAttentionConv32Rnn128-BN-lr0.005-ae0.01-1/
export CUDA_VISIBLE_DEVICES=1; python v4-birnn.py --training_data=/home/hotdogee/datasets2/pfam-regions-d0-s20-train.tfrecords --eval_data=/home/hotdogee/datasets2/pfam-regions-d0-s20-test.tfrecords --metadata_path=/home/hotdogee/datasets2/pfam-regions-d0-s20-meta.json --num_classes=16715 --batch_size=2 --save_summary_steps=200 --log_step_count_steps=200 --learning_rate_decay_steps=350000 --learning_rate_decay_rate=0.9 --learning_rate=0.03 --adam_epsilon=0.05 --save_checkpoints_secs=3600 --keep_checkpoint_max=24 --use_crf=False --use_conv_batch_norm=False --use_rnn_batch_norm=False --rnn_cell_type=LayerNormLSTMCellv2 --use_conv_1_bank=False --conv_1_filters=32 --conv_1_bank_size=16 --conv_1_strides=1 --use_conv_1_residual=False --use_conv_1_highway=False --conv_1_highway_depth=3 --conv_1_highway_units=32  --use_conv_1_prenet=False --conv_1_prenet_dropout=0.2 --use_batch_renorm=False  --use_conv_1_attention=False --attention_key_channels=32 --attention_value_channels=32 --attention_hidden_size=32 --attention_num_heads=1 --attention_dropout=0.0 --attention_type=local_unmasked --attention_block_length=128 --attention_filter_width=64 --use_conv_1_attention_batch_norm=False --use_rnn_attention=False --rnn_attention_hidden_size=128 --use_rnn_attention_batch_norm=False --use_rnn_peepholes=False --model_dir=/data/checkpoints/pfam-regions-d0-s20/2690V4-1080Ti/v4-birnn/LayerNormLSTMCellv2-no_bn-lr0.03-ae0.05-1
